{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model explanation with LIME\n",
    "\n",
    "We will use the [speed dating](https://www.openml.org/d/40536) dataset and train random forest and XGoost classifiers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing observations to explain\n",
    "\n",
    "At first we will look at XGBoost classifier.\n",
    "\n",
    "We will choose 3 observations to explain:\n",
    "- one where the model is very confident and is correct\n",
    "- one where the model is very confident and is wrong\n",
    "- one where the model is not very confident, the probability of the predicted class is close to 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking stability\n",
    "\n",
    "We will test the stability of explonations by running the same explainer on the same observation multiple times.\n",
    "\n",
    "### Explonation for the observation where the model is very confident and is correct\n",
    "<div style=\"display: flex; justify-content: space-around;\">\n",
    "  <img src=\"img/certain_correct_0.png\" width=\"30%\">\n",
    "  <img src=\"img/certain_correct_1.png\" width=\"30%\">\n",
    "  <img src=\"img/certain_correct_2.png\" width=\"30%\">\n",
    "</div>\n",
    "\n",
    "### Explanation for the observation where the model is very confident and is wrong\n",
    "<div style=\"display: flex; justify-content: space-around;\">\n",
    "  <img src=\"img/certain_incorrect_0.png\" width=\"30%\">\n",
    "  <img src=\"img/certain_incorrect_1.png\" width=\"30%\">\n",
    "  <img src=\"img/certain_incorrect_2.png\" width=\"30%\">\n",
    "</div>\n",
    "\n",
    "\n",
    "### Edge case observation (model is not confident about it's prediction)\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-around;\">\n",
    "  <img src=\"img/edge_case_0.png\" width=\"30%\">\n",
    "  <img src=\"img/edge_case_1.png\" width=\"30%\">\n",
    "  <img src=\"img/edge_case_2.png\" width=\"30%\">\n",
    "</div>\n",
    "\n",
    "\n",
    "As we see there can be some variation in explonations during multiple runs, but generally when the explainer find some feature the most important then in most cases it will be the same feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences between explonations for different models\n",
    "\n",
    "Here we will pick few observations where:\n",
    "- models are confident and give the same predictions\n",
    "- models are confident but give different predictions\n",
    "\n",
    "and check, how the explonations differ.\n",
    "\n",
    "\n",
    "### Models are confident and give the same predictions\n",
    "<div style=\"display: flex; justify-content: center;margin-bottom:10px;\">\n",
    "    <img src=\"img/same_classes_ob_0_xgb.png\" width=\"40%\">\n",
    "    <img src=\"img/same_classes_ob_0_rf.png\" width=\"40%\">\n",
    "</div>\n",
    "<div style=\"display: flex; justify-content: center;margin-bottom:10px;\">\n",
    "    <img src=\"img/same_classes_ob_1_xgb.png\" width=\"40%\">\n",
    "    <img src=\"img/same_classes_ob_1_rf.png\" width=\"40%\">\n",
    "</div>\n",
    "<div style=\"display: flex; justify-content: center; margin-bottom:10px;\">\n",
    "    <img src=\"img/same_classes_ob_1_xgb.png\" width=\"40%\">\n",
    "    <img src=\"img/same_classes_ob_1_rf.png\" width=\"40%\">\n",
    "</div>\n",
    "\n",
    "When multiple models predict the same outcome, they generally point to the same feature that is the most important for the predicted class.\n",
    "They also tend to highlight similar feature that is important for the opposite to predicted class.\n",
    "\n",
    "The explonations differ on less important features quite a lot.\n",
    "\n",
    "\n",
    "### Models are confident and give different predictions\n",
    "<div style=\"display: flex; justify-content: center;margin-bottom:10px;\">\n",
    "    <img src=\"img/different_classes_ob_0_xgb.png\" width=\"40%\">\n",
    "    <img src=\"img/different_classes_ob_0_rf.png\" width=\"40%\">\n",
    "</div>\n",
    "<div style=\"display: flex; justify-content: center;margin-bottom:10px;\">\n",
    "    <img src=\"img/different_classes_ob_1_xgb.png\" width=\"40%\">\n",
    "    <img src=\"img/different_classes_ob_1_rf.png\" width=\"40%\">\n",
    "</div>\n",
    "<div style=\"display: flex; justify-content: center; margin-bottom:10px;\">\n",
    "    <img src=\"img/different_classes_ob_1_xgb.png\" width=\"40%\">\n",
    "    <img src=\"img/different_classes_ob_1_rf.png\" width=\"40%\">\n",
    "</div>\n",
    "\n",
    "In this case, the explainers of course do not agree on the overall importances of features for the prediction,\n",
    "but if one explainer identifies feature X has a positive weight for class 1, the other explainer typically agrees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
